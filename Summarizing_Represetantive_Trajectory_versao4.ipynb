{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## using Jinja2 for Text Summarization\n",
        "# Jinja2 to dynamically generate the refined summary for your trajectory data\n",
        "\n",
        "!pip install Jinja2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiXSvDvc7QIu",
        "outputId": "f8bb05e2-5a53-424e-e8a6-10a64e3912ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.11/dist-packages (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os #Importa o módulo os, que fornece funcionalidades para manipulação de arquivos e diretórios.\n",
        "import re #Importa o módulo re para manipulação e análise de expressões regulares.\n",
        "from collections import defaultdict #Importa defaultdict, um dicionário especial que permite definir valores padrão para chaves inexistentes.\n",
        "from jinja2 import Template # Importa Template da biblioteca Jinja2, usada para gerar textos formatados dinamicamente.\n",
        "global aspects # Declara aspects como uma variável global para armazenar os aspectos (atributos) analisados posteriormente no código\n",
        "\n",
        "\n",
        "\n",
        "#Define o caminho do arquivo que contém os dados representativos.\n",
        "\n",
        "#representative_data_path = '/content/Running_Example_v5_rt 0 0 .csv'\n",
        "representative_data_path = '/content/Running_Example_v5_rt 15 10.csv'\n",
        "\n",
        "\n",
        "\n",
        "#Verifica se o arquivo existe. Se não, lança um erro FileNotFoundError.\n",
        "\n",
        "if not os.path.exists(representative_data_path):\n",
        "    raise FileNotFoundError(f\"File not found: {representative_data_path}\")\n",
        "\n",
        "\n",
        "\n",
        "#Abre o arquivo em modo leitura ('r') com codificação UTF-8.\n",
        "#Lê todas as linhas do arquivo e armazena na variável representative_data_raw.\n",
        "#Se houver erro ao ler o arquivo, lança um erro RuntimeError.\n",
        "\n",
        "try:\n",
        "    with open(representative_data_path, 'r', encoding='utf-8') as file:\n",
        "          representative_data_raw = file.readlines()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Error reading file: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "#Define a função pre_processing, responsável por processar os dados do arquivo.\n",
        "\n",
        "def pre_processing():\n",
        "\n",
        "  # Parse the representative file to extract structured information\n",
        "  def parse_representative_data(raw_lines):\n",
        "    global aspects\n",
        "\n",
        "\n",
        "    #Cria um dicionário para armazenar três seções: metadata, settings e trajectory_description.\n",
        "    parsed_data = {\n",
        "        \"metadata\": {},\n",
        "        \"settings\": {},\n",
        "        \"trajectory_description\": []\n",
        "    }\n",
        "\n",
        "\n",
        "    #Remove espaços extras no início e fim de cada linha.\n",
        "    current_section = None\n",
        "    for line in raw_lines:\n",
        "        line = line.strip()\n",
        "\n",
        "\n",
        "        #Identifica qual seção do arquivo está sendo processada e define current_section de acordo.\n",
        "        if \"Info input dataset:\" in line:\n",
        "            current_section = \"metadata\"\n",
        "        elif \"RT setting infos:\" in line:\n",
        "            current_section = \"settings\"\n",
        "        elif \"RT description:\" in line:\n",
        "            current_section = \"trajectory_description\"\n",
        "        elif line.startswith(\"##\"):\n",
        "            current_section = None  # End of a section\n",
        "\n",
        "\n",
        "        #Se estiver na seção metadata, armazena os pares chave-valor.\n",
        "        elif current_section == \"metadata\":\n",
        "            # Parse metadata key-value pairs\n",
        "            if re.match(r'\\|.*\\|', line):  # Header line for metadata\n",
        "                headers = [h.strip() for h in line.split(\",\")]\n",
        "            else:\n",
        "                values = [v.strip() for v in line.split(\",\")]\n",
        "                for h, v in zip(headers, values):\n",
        "                    parsed_data[\"metadata\"][h] = v\n",
        "\n",
        "\n",
        "        #Se estiver na seção settings, armazena as configurações do arquivo.\n",
        "        elif current_section == \"settings\":\n",
        "            # Parse settings details\n",
        "            if re.match(r'thresholdCellSize', line):  # Header line for settings\n",
        "                settings_headers = [h.strip() for h in line.split(\",\")]\n",
        "            else:\n",
        "                settings_values = [v.strip() for v in line.split(\",\")]\n",
        "                for h, v in zip(settings_headers, settings_values):\n",
        "                    parsed_data[\"settings\"][h] = v\n",
        "\n",
        "\n",
        "        #Se estiver na seção trajectory_description, armazena os dados da trajetória do objeto.\n",
        "        elif current_section == \"trajectory_description\":\n",
        "            # Parse trajectory description lines\n",
        "            if re.match(r'lat_lon', line):  # Header line for trajectory description\n",
        "                trajectory_headers = [h.strip() for h in line.split(\",\")]\n",
        "            else:\n",
        "                trajectory_values = [v.strip() for v in line.split(\",\")]\n",
        "                parsed_data[\"trajectory_description\"].append(\n",
        "                    dict(zip(trajectory_headers, trajectory_values))\n",
        "                )\n",
        "\n",
        "\n",
        "            #Define aspects globalmente para armazenar os aspectos analisados.\n",
        "            aspects = trajectory_headers\n",
        "    return parsed_data\n",
        "\n",
        "\n",
        "\n",
        "  #Processa os dados do arquivo e imprime a estrutura gerada.\n",
        "  structured_data = parse_representative_data(representative_data_raw)\n",
        "  print(structured_data)\n",
        "\n",
        "\n",
        "  #Define os aspectos a serem analisados: Ponto de Interesse (POI) e Clima (WEATHER).\n",
        "  aspects_to_analyze = ['POI', 'WEATHER']\n",
        "\n",
        "\n",
        "\n",
        "  #Analisa padrões comuns nos aspectos especificados.\n",
        "  def analyze_aspect_patterns(data, aspects):\n",
        "      \"\"\"Analyzes trajectory data for common patterns in specified aspects.\"\"\"\n",
        "      trajectory = data[\"trajectory_description\"]\n",
        "      aspects_to_analyze = aspects\n",
        "\n",
        "\n",
        "\n",
        "      #Cria um dicionário para armazenar contagens de valores observados nos aspectos.\n",
        "      patterns = defaultdict(lambda: {\"values\": defaultdict(int), \"count\": 0})\n",
        "\n",
        "\n",
        "\n",
        "      # Itera sobre a descrição da trajetória.\n",
        "      for aspect in trajectory:\n",
        "        print(f\"Aspect: {aspect}\")\n",
        "\n",
        "\n",
        "\n",
        "        # Conta quantas vezes cada valor aparece para cada aspecto.\n",
        "        for aspect_name in aspects_to_analyze:\n",
        "          if aspect_name in aspect:\n",
        "              patterns[aspect_name][\"count\"] += 1\n",
        "              patterns[aspect_name][\"values\"][aspect[aspect_name]] += 1\n",
        "\n",
        "      summary_parts = []\n",
        "\n",
        "      for aspect_name, pattern_data in patterns.items():\n",
        "          if pattern_data[\"count\"] > 0:\n",
        "              values_dict = pattern_data[\"values\"]\n",
        "              if len(values_dict) == 1:\n",
        "                  value = next(iter(values_dict))\n",
        "                  summary_parts.append(f\"Usually, the object's {aspect_name.lower()} is {value}\")\n",
        "              elif aspect_name == 'PRICE':\n",
        "                  prices = []\n",
        "                  for key, value in values_dict.items():\n",
        "                    match = re.findall(r'\\*(\\d+):\\s*([\\d\\.]+)', key)\n",
        "                    if match:\n",
        "                        for m in match:\n",
        "                          prices.append(float(m[0]))\n",
        "\n",
        "                  if prices:\n",
        "                    min_price = min(prices)\n",
        "                    max_price = max(prices)\n",
        "                    summary_parts.append(f\"The evaluation of price in referred place is defined between {min_price} and {max_price}\")\n",
        "\n",
        "              else:\n",
        "                  most_frequent_value = max(pattern_data[\"values\"], key=pattern_data[\"values\"].get)\n",
        "                  if pattern_data[\"values\"][most_frequent_value] == pattern_data[\"count\"]:\n",
        "                    summary_parts.append(f\"Usually, the object's {aspect_name.lower()} is {most_frequent_value}\")\n",
        "\n",
        "      return \" \".join(summary_parts)\n",
        "\n",
        "\n",
        "\n",
        "  # Gera um resumo dos dados processados.\n",
        "  def generate_summary(data):\n",
        "\n",
        "\n",
        "\n",
        "      # Resume a quantidade de trajetórias e pontos.\n",
        "      metadata_summary = (\n",
        "          f\"The representative dataset contains {data['metadata'].get('|input.T|', 'N/A')} trajectories \"\n",
        "          f\"with a total of {data['metadata'].get('|input.T.points|', 'N/A')} points.\\n\"\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "      # Resume as configurações utilizadas na análise.\n",
        "      settings = data[\"settings\"]\n",
        "      settings_summary = (\n",
        "          \"The analysis used the following parameters:\\n\"\n",
        "          f\"- Threshold Cell Size: {settings.get('thresholdCellSize', 'N/A')}\\n\"\n",
        "          f\"- Cell Size: {settings.get('CellSize', 'N/A')}\\n\"\n",
        "          f\"- Relevant Cell Threshold: {settings.get('tauRelevantCell', 'N/A')}\\n\"\n",
        "          f\"- Representativeness Value Threshold: {settings.get('tauRepresentativenessValue', 'N/A')}\\n\"\n",
        "          f\"- Runtime: {settings.get('runtime start', 'N/A')} to {settings.get('runtime end', 'N/A')}.\\n\"\n",
        "      )\n",
        "\n",
        "      # Trajectory description summary\n",
        "      trajectory = data[\"trajectory_description\"]\n",
        "\n",
        "\n",
        "\n",
        "      # Lista eventos da trajetória do objeto.\n",
        "      trajectory_summary = \"Key trajectory events:\\n\"\n",
        "      for aspect in trajectory:\n",
        "          trajectory_summary += (\n",
        "              f\"  - At {aspect.get('time', 'N/A')}, the object was at location {aspect.get('lat_lon', 'N/A')} \"\n",
        "              f\"({aspect.get('POI', 'N/A')}) under {aspect.get('WEATHER', 'N/A')} weather conditions \"\n",
        "              f\"with precipitation of {aspect.get('PRECIP', 'N/A')} mm.\\n\"\n",
        "          )\n",
        "\n",
        "\n",
        "\n",
        "      # Chama a função de análise de padrões.\n",
        "      trajectory_patterns_summary = analyze_aspect_patterns(data, aspects=aspects_to_analyze)\n",
        "\n",
        "\n",
        "\n",
        "      # Retorna um resumo completo.\n",
        "      summary = metadata_summary + settings_summary + trajectory_summary + trajectory_patterns_summary\n",
        "      return summary\n",
        "\n",
        "\n",
        "\n",
        "  # Generate a summary for the representative data\n",
        "  summary = generate_summary(structured_data)\n",
        "\n",
        "\n",
        "\n",
        "  # Classifica um horário em manhã, tarde, noite ou madrugada.\n",
        "  def time_of_day(hour):\n",
        "      \"\"\"Categorize an hour into morning, afternoon, evening, or night.\"\"\"\n",
        "      if 5 <= hour < 12:\n",
        "          return \"morning\"\n",
        "      elif 12 <= hour < 17:\n",
        "          return \"afternoon\"\n",
        "      elif 17 <= hour < 21:\n",
        "          return \"evening\"\n",
        "      else:\n",
        "          return \"night\"\n",
        "\n",
        "\n",
        "\n",
        "  # Formata descrições de POI.\n",
        "  def format_poi(poi):\n",
        "      \"\"\"Format POI descriptions to be more human-readable.\"\"\"\n",
        "      if \"1.0\" in poi:  # If the frequency is 100%, use a simpler phrase\n",
        "          poi_name = poi.split(\":\")[0].strip(\"{}\")  # Extract the POI name\n",
        "          return f\"at {poi_name.lower()}\"\n",
        "\n",
        "      return poi.replace(\"at \", \"\").strip()  # Remove extra \"at\" from transitions\n",
        "\n",
        "\n",
        "\n",
        "  # Formata informações meteorológicas.\n",
        "  def format_weather(weather):\n",
        "      \"\"\"Format weather conditions to include frequency density.\"\"\"\n",
        "      matches = re.findall(r'{(.*?):\\s*([\\d\\.]+)}', weather)\n",
        "      if matches:\n",
        "          conditions = []\n",
        "          for condition, freq in matches:\n",
        "              freq = float(freq)\n",
        "              if freq == 1.0:\n",
        "                  conditions.append(f\"{condition.lower()} (100% frequency)\")\n",
        "              else:\n",
        "                  percentage = int(freq * 100)\n",
        "                  conditions.append(f\"{condition.lower()} ({percentage}%)\")\n",
        "          return \" and \".join(conditions)\n",
        "\n",
        "\n",
        "      return weather\n",
        "\n",
        "  return structured_data, time_of_day, format_weather, format_poi\n",
        "\n",
        "\n",
        "\n",
        "# Chama a função pre_processing, que retorna os dados processados e funções auxiliares.\n",
        "structured_data, time_of_day, format_weather, format_poi = pre_processing()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zPn9aYevUIoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c08189ff-a174-4d6d-e7d6-a1650253c26d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'metadata': {'|input.T|': '3', '|input.T.points|': '17'}, 'settings': {'thresholdCellSize': '9', 'CellSize': '4.602687082099914', 'tauRelevantCell': '0.15', 'tauRepresentativenessValue': '0.1', '|cell|': '5', 'minPointRC': '2.5500002', '|rt|': '14', '|coverPoints|': '16', 'runtime start': '23-07-07 14:41:12.958', 'runtime end': '23-07-07 14:41:13.275'}, 'trajectory_description': [{'lat_lon': '0.0 6.2', 'time': '05:45', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{1: 1}'}, {'lat_lon': '0.4 6.7', 'time': '06:15', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '15.0', 'mapping': '{2: 7}'}, {'lat_lon': '1.0 6.8', 'time': '06:50', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{3: 13}'}, {'lat_lon': '2.5 10.5', 'time': '10:10', 'PRICE': '{*2: 1.0}', 'POI': '{LIBRARY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{2: 8}'}, {'lat_lon': '4.0 14.5', 'time': '10:35', 'PRICE': '{*2: 1.0}', 'POI': '{SHOPPING: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{3: 14}'}, {'lat_lon': '0.8 6.2', 'time': '11:57', 'PRICE': '{*2: 1.0}', 'POI': '{LIBRARY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '20.0', 'mapping': '{1: 2}'}, {'lat_lon': '3.0 13.5', 'time': '12:20', 'PRICE': '{*3: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '20.0', 'mapping': '{2: 9}'}, {'lat_lon': '4.3 17.9', 'time': '14:15', 'PRICE': '{*-1: 1.0}', 'POI': '{UNIVERSITY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{3: 15}'}, {'lat_lon': '3.1 11.0', 'time': '17:12', 'PRICE': '{*2: 1.0}', 'POI': '{SHOPPING: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{1: 3}'}, {'lat_lon': '6.3 13.1', 'time': '18:00', 'PRICE': '{*1: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{3: 16}'}, {'lat_lon': '4.3 16.9', 'time': '19:39', 'PRICE': '{*-1: 1.0}', 'POI': '{UNIVERSITY: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '0.0', 'mapping': '{1: 4}'}, {'lat_lon': '6.3 13.0', 'time': '21:23', 'PRICE': '{*1: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{2: 11}'}, {'lat_lon': '6.2 12.05', 'time': '22:15 - 22:24', 'PRICE': '{*1: 0.5; *2: 0.5}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '5.0', 'mapping': '{1: 5; 3: 17}'}, {'lat_lon': '0.5 6.55', 'time': '23:20 - 23:30', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '12.5', 'mapping': '{1: 6; 2: 12}'}]}\n",
            "Aspect: {'lat_lon': '0.0 6.2', 'time': '05:45', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{1: 1}'}\n",
            "Aspect: {'lat_lon': '0.4 6.7', 'time': '06:15', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '15.0', 'mapping': '{2: 7}'}\n",
            "Aspect: {'lat_lon': '1.0 6.8', 'time': '06:50', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{3: 13}'}\n",
            "Aspect: {'lat_lon': '2.5 10.5', 'time': '10:10', 'PRICE': '{*2: 1.0}', 'POI': '{LIBRARY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{2: 8}'}\n",
            "Aspect: {'lat_lon': '4.0 14.5', 'time': '10:35', 'PRICE': '{*2: 1.0}', 'POI': '{SHOPPING: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{3: 14}'}\n",
            "Aspect: {'lat_lon': '0.8 6.2', 'time': '11:57', 'PRICE': '{*2: 1.0}', 'POI': '{LIBRARY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '20.0', 'mapping': '{1: 2}'}\n",
            "Aspect: {'lat_lon': '3.0 13.5', 'time': '12:20', 'PRICE': '{*3: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '20.0', 'mapping': '{2: 9}'}\n",
            "Aspect: {'lat_lon': '4.3 17.9', 'time': '14:15', 'PRICE': '{*-1: 1.0}', 'POI': '{UNIVERSITY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{3: 15}'}\n",
            "Aspect: {'lat_lon': '3.1 11.0', 'time': '17:12', 'PRICE': '{*2: 1.0}', 'POI': '{SHOPPING: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{1: 3}'}\n",
            "Aspect: {'lat_lon': '6.3 13.1', 'time': '18:00', 'PRICE': '{*1: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{3: 16}'}\n",
            "Aspect: {'lat_lon': '4.3 16.9', 'time': '19:39', 'PRICE': '{*-1: 1.0}', 'POI': '{UNIVERSITY: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '0.0', 'mapping': '{1: 4}'}\n",
            "Aspect: {'lat_lon': '6.3 13.0', 'time': '21:23', 'PRICE': '{*1: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{2: 11}'}\n",
            "Aspect: {'lat_lon': '6.2 12.05', 'time': '22:15 - 22:24', 'PRICE': '{*1: 0.5; *2: 0.5}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '5.0', 'mapping': '{1: 5; 3: 17}'}\n",
            "Aspect: {'lat_lon': '0.5 6.55', 'time': '23:20 - 23:30', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '12.5', 'mapping': '{1: 6; 2: 12}'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from pickle import EMPTY_DICT\n",
        "\n",
        "import re\n",
        "from datetime import datetime # Importa a classe datetime, utilizada para manipular e formatar datas e horas.\n",
        "from jinja2 import Template # Importa Template da biblioteca jinja2, que permite criar templates para gerar texto estruturado.\n",
        "\n",
        "\n",
        "\n",
        "# Define a função textual_descriptor, que gera uma descrição textual baseada nos dados estruturados de trajetórias (structured_data).\n",
        "# Também recebe as funções auxiliares time_of_day, format_weather e format_poi, usadas para classificar horários, formatar condições climáticas e locais visitados.\n",
        "def textual_descriptor(structured_data, time_of_day, format_weather, format_poi):\n",
        "\n",
        "  '''\n",
        "  função já faz parte do 'Textual Descriptor'.\n",
        "\n",
        "  '''\n",
        "\n",
        "\n",
        "\n",
        "  # Define uma função interna para gerar um resumo narrativo dos eventos de trajetória.\n",
        "  def generate_narrative_summary(data):\n",
        "      \"\"\"Generate a narrative summary of the trajectory data.\"\"\"\n",
        "      trajectory = data[\"trajectory_description\"]\n",
        "\n",
        "      # Group events by time of day\n",
        "      time_groups = defaultdict(list)\n",
        "      for event in trajectory:\n",
        "          time_str = event.get(\"time\", \"\").split(\"-\")[0].strip()  # Use start time and strip trailing space\n",
        "          hour = int(time_str.split(\":\")[0])  # Extract the hour\n",
        "          period = time_of_day(hour)\n",
        "          time_groups[period].append(event)\n",
        "\n",
        "      # Generate narrative for each time group\n",
        "      summary_parts = []\n",
        "      for period, events in time_groups.items():\n",
        "          poi_counts = defaultdict(int)\n",
        "          weather_counts = defaultdict(int)\n",
        "          transitions = []\n",
        "\n",
        "          for i, event in enumerate(events):\n",
        "              poi = event.get(\"POI\", \"N/A\")\n",
        "              weather = event.get(\"WEATHER\", \"N/A\")\n",
        "              poi_counts[poi] += 1\n",
        "              weather_counts[weather] += 1\n",
        "\n",
        "              # Track transitions between locations\n",
        "              if i > 0:\n",
        "                  prev_poi = events[i - 1].get(\"POI\", \"N/A\")\n",
        "                  if poi != prev_poi:\n",
        "                      transitions.append(\n",
        "                          f\"At {event['time']}, the object moved from {format_poi(prev_poi)} to at {format_poi(poi)}.\"\n",
        "                      )\n",
        "\n",
        "          # Summarize the most frequent POI and weather\n",
        "          most_common_poi = max(poi_counts, key=poi_counts.get)\n",
        "          most_common_weather = max(weather_counts, key=weather_counts.get)\n",
        "          formatted_weather = format_weather(most_common_weather)\n",
        "          summary_parts.append(\n",
        "              f\"In the {period}, the object is usually {format_poi(most_common_poi)} \"\n",
        "              f\"with weather conditions {formatted_weather}.\"\n",
        "          )\n",
        "\n",
        "          # Add transitions if they exist\n",
        "          if transitions:\n",
        "              summary_parts.extend(transitions)\n",
        "\n",
        "      # Combine all summaries into a cohesive narrative\n",
        "      return \" \".join(summary_parts)\n",
        "\n",
        "  # Example usage:\n",
        "  narrative_summary = generate_narrative_summary(structured_data)\n",
        "  #print(narrative_summary)\n",
        "\n",
        "  def refine_summary_text(summary_text):\n",
        "      \"\"\"Refines the summary text to improve readability and remove redundant words.\"\"\"\n",
        "      summary_text = summary_text.replace(\"frequently in \", \"at \")\n",
        "      summary_text = summary_text.replace(\"with weather conditions\", \"with\")\n",
        "\n",
        "      # Improve readability by ensuring correct sentence structure\n",
        "      #summary_text = re.sub(r'\\s+', ' ', summary_text)  # Remove extra spaces\n",
        "      #summary_text = summary_text.replace(\" - \", \"–\")  # Replace hyphen with en dash for time ranges\n",
        "\n",
        "      return summary_text\n",
        "\n",
        "  # Normalize spaces & replace dashes once, instead of in multiple places\n",
        "  def preprocess_text(input_text):\n",
        "      \"\"\"Cleans and normalizes input text for parsing.\"\"\"\n",
        "      input_text = re.sub(r\"\\s+\", \" \", input_text.strip())  # Normalize spaces\n",
        "      input_text = input_text.replace(\" - \", \"–\")  # Replace dashes\n",
        "      input_text = input_text.replace(\"–\", \"-\")\n",
        "      return input_text\n",
        "\n",
        "  refined_summary = refine_summary_text(narrative_summary)\n",
        "  print(refined_summary)\n",
        "\n",
        "  usuario = input(\"Digite o nome do usuário (ou pressione Enter para usar 'The object'): \").strip()\n",
        "  if not usuario:\n",
        "      usuario = \"object\"  # Default value\n",
        "\n",
        "\n",
        "  # Template de saída\n",
        "  '''\n",
        "\n",
        "  '''\n",
        "  template_text = \"\"\"\n",
        "  {% for period in data %}\n",
        "  In the {{ period.time_period }}, the \"\"\" + usuario + \"\"\" is usually at {{ period.poi }}{% if period.weather and \"100% frequency\" not in period.weather %} with {{ period.weather }}{% endif %}.\n",
        "  {% for transition in period.transitions %}\n",
        "  At {{ transition.time }}, the \"\"\" + usuario + \"\"\" moves from {{ transition.from_poi }} to {{ transition.to_poi.split(',')[0] }}.{% if not loop.last %} Then, {% endif %}\n",
        "  {% endfor %}\n",
        "  {% endfor %}\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  input_text = preprocess_text(refined_summary)\n",
        "\n",
        "  def parse_input_text(input_text):\n",
        "      \"\"\"Analisa o texto e estrutura os dados para o template.\"\"\"\n",
        "      time_period_pattern = r\"In the (\\w+), the object is usually at ([\\w\\s]+)(?: with [\\w\\s]+ \\(\\d+% frequency\\))?\\.\"\n",
        "      transition_pattern = r\"At\\s+([\\d:–]+)(?:-\\d{2}:\\d{2})?, the object moved from(?: at)? ([\\w\\s]+) to(?: at)? (?:\\{([^}]+)\\}|([\\w\\s]+))\\.\"\n",
        "\n",
        "      # Extrair períodos do dia\n",
        "      time_periods = re.findall(time_period_pattern, input_text)\n",
        "\n",
        "      # Extrair transições\n",
        "      transitions = re.findall(transition_pattern, input_text)\n",
        "      #print(transitions)\n",
        "\n",
        "      def extract_best_destination(to_pois):\n",
        "          \"\"\"Extracts the best destination based on frequency values.\"\"\"\n",
        "          if not to_pois:\n",
        "              return \"unknown location\"\n",
        "\n",
        "          destinations = re.findall(r\"([A-Z]+): ([\\d.]+)\", to_pois)\n",
        "          if destinations:\n",
        "              best_destination = sorted(destinations, key=lambda x: (-float(x[1]), x[0]))[0][0]\n",
        "              return best_destination\n",
        "          return to_pois.strip()\n",
        "\n",
        "\n",
        "      def get_period_for_time(time_str):\n",
        "          \"\"\"Retorna o período do dia baseado na hora fornecida.\"\"\"\n",
        "          period_boundaries = {\n",
        "              \"morning\": (6, 11),\n",
        "              \"afternoon\": (12, 17),\n",
        "              \"evening\": (18, 21),\n",
        "              \"night\": (22, 5),  # Night começa às 22:00 e vai até 05:59\n",
        "          }\n",
        "\n",
        "          time_obj = datetime.strptime(time_str, \"%H:%M\")\n",
        "          hour = time_obj.hour\n",
        "\n",
        "          for period, (start_hour, end_hour) in period_boundaries.items():\n",
        "              if start_hour <= end_hour:  # Intervalos normais (morning, afternoon, evening)\n",
        "                  if start_hour <= hour <= end_hour:\n",
        "                      return period\n",
        "              else:  # Caso especial para \"night\" que cruza a meia-noite (22h - 05h)\n",
        "                  if hour >= start_hour or hour <= end_hour:\n",
        "                      return period\n",
        "          return \"night\"\n",
        "\n",
        "      # Estruturar os dados com as transições divididas por período\n",
        "      structured_data = []\n",
        "      for time_period, poi in time_periods:\n",
        "          transitions_in_period = []\n",
        "\n",
        "          # Filtrar transições para o período atual\n",
        "\n",
        "          for time, from_poi, to_pois_1, to_pois_2 in transitions:\n",
        "                period = get_period_for_time(time)\n",
        "                to_pois = to_pois_1 if to_pois_1 else to_pois_2  # Ensure correct destination format\n",
        "\n",
        "                if period == time_period.lower():\n",
        "                    best_destination = extract_best_destination(to_pois)\n",
        "                    transitions_in_period.append({\n",
        "                        \"time\": time.strip(),\n",
        "                        \"from_poi\": from_poi.strip(),\n",
        "                        \"to_poi\": best_destination.strip(),\n",
        "                    })\n",
        "\n",
        "\n",
        "          structured_data.append({\n",
        "              \"time_period\": time_period.lower(),\n",
        "              \"poi\": poi.strip(),\n",
        "              \"transitions\": transitions_in_period\n",
        "          })\n",
        "\n",
        "      return structured_data\n",
        "\n",
        "  def generate_summary(data):\n",
        "      \"\"\"Gera um resumo\"\"\"\n",
        "      summary = []\n",
        "      for period in data:\n",
        "          transitions = period[\"transitions\"]\n",
        "          summary.append(\n",
        "              f\"In the {period['time_period']}, the {usuario} is usually at {period['poi']}.\"\n",
        "          )\n",
        "          if transitions:\n",
        "              for transition in transitions:\n",
        "                  summary.append(\n",
        "                      f\"Then the {usuario} goes to {transition['to_poi']}.\"\n",
        "                  )\n",
        "      return \"\\n\".join(summary)\n",
        "\n",
        "  # Parse do texto de entrada\n",
        "  structured_data = parse_input_text(input_text)\n",
        "\n",
        "  # Verificar se a transição foi reconhecida\n",
        "  '''\n",
        "  for period in structured_data_new:\n",
        "      print(f\"Período: {period['time_period']}, Transições: {period['transitions']}\")\n",
        "  '''\n",
        "\n",
        "  # Renderizar o template\n",
        "  template = Template(template_text)\n",
        "  output_jinja = template.render(data=structured_data)\n",
        "\n",
        "  summary = generate_summary(structured_data)\n",
        "\n",
        "  # Imprimir os resultados\n",
        "  print(\"=== Texto Gerado ===\")\n",
        "  print(output_jinja)\n",
        "  print(\"\\n=== Resumo ===\")\n",
        "  print(summary)\n",
        "\n",
        "textual_descriptor(structured_data, time_of_day, format_weather, format_poi)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OEQCQSB50Wp",
        "outputId": "a81a0470-1b1d-4be5-f11d-5d24a08feaa4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the morning, the object is usually at home with weather conditions clear (100% frequency). At 10:10, the object moved from at home to at at library. At 10:35, the object moved from at library to at at shopping. At 11:57, the object moved from at shopping to at at library. In the afternoon, the object is usually at restaurant with weather conditions clouds (100% frequency). At 14:15, the object moved from at restaurant to at at university. In the evening, the object is usually at shopping with weather conditions clear (100% frequency). At 18:00, the object moved from at shopping to at at restaurant. At 19:39, the object moved from at restaurant to at at university. In the night, the object is usually at restaurant with weather conditions clear (100% frequency). At 23:20 - 23:30, the object moved from at restaurant to at at home.\n",
            "In the morning, the object is usually at home with clear (100% frequency). At 10:10, the object moved from at home to at at library. At 10:35, the object moved from at library to at at shopping. At 11:57, the object moved from at shopping to at at library. In the afternoon, the object is usually at restaurant with clouds (100% frequency). At 14:15, the object moved from at restaurant to at at university. In the evening, the object is usually at shopping with clear (100% frequency). At 18:00, the object moved from at shopping to at at restaurant. At 19:39, the object moved from at restaurant to at at university. In the night, the object is usually at restaurant with clear (100% frequency). At 23:20 - 23:30, the object moved from at restaurant to at at home.\n",
            "Digite o nome do usuário (ou pressione Enter para usar 'The object'): test\n",
            "=== Texto Gerado ===\n",
            "\n",
            "  \n",
            "  In the morning, the test is usually at home.\n",
            "  \n",
            "  At 10:10, the test moves from home to at library. Then, \n",
            "  \n",
            "  At 10:35, the test moves from library to at shopping. Then, \n",
            "  \n",
            "  At 11:57, the test moves from shopping to at library.\n",
            "  \n",
            "  \n",
            "  In the afternoon, the test is usually at restaurant.\n",
            "  \n",
            "  At 14:15, the test moves from restaurant to at university.\n",
            "  \n",
            "  \n",
            "  In the evening, the test is usually at shopping.\n",
            "  \n",
            "  At 18:00, the test moves from shopping to at restaurant. Then, \n",
            "  \n",
            "  At 19:39, the test moves from restaurant to at university.\n",
            "  \n",
            "  \n",
            "  In the night, the test is usually at restaurant.\n",
            "  \n",
            "  At 23:20, the test moves from restaurant to at home.\n",
            "  \n",
            "  \n",
            "  \n",
            "\n",
            "=== Resumo ===\n",
            "In the morning, the test is usually at home.\n",
            "Then the test goes to at library.\n",
            "Then the test goes to at shopping.\n",
            "Then the test goes to at library.\n",
            "In the afternoon, the test is usually at restaurant.\n",
            "Then the test goes to at university.\n",
            "In the evening, the test is usually at shopping.\n",
            "Then the test goes to at restaurant.\n",
            "Then the test goes to at university.\n",
            "In the night, the test is usually at restaurant.\n",
            "Then the test goes to at home.\n"
          ]
        }
      ]
    }
  ]
}
