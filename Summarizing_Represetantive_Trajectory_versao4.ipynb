{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## using Jinja2 for Text Summarization\n",
        "# Jinja2 to dynamically generate the refined summary for your trajectory data\n",
        "\n",
        "!pip install Jinja2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiXSvDvc7QIu",
        "outputId": "f8bb05e2-5a53-424e-e8a6-10a64e3912ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.11/dist-packages (3.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os #Importa o módulo os, que fornece funcionalidades para manipulação de arquivos e diretórios.\n",
        "import re #Importa o módulo re para manipulação e análise de expressões regulares.\n",
        "from collections import defaultdict #Importa defaultdict, um dicionário especial que permite definir valores padrão para chaves inexistentes.\n",
        "from jinja2 import Template # Importa Template da biblioteca Jinja2, usada para gerar textos formatados dinamicamente.\n",
        "global aspects # Declara aspects como uma variável global para armazenar os aspectos (atributos) analisados posteriormente no código\n",
        "\n",
        "\n",
        "\n",
        "#Define o caminho do arquivo que contém os dados representativos.\n",
        "#Defines the path of the file containing the representative data.\n",
        "\n",
        "#representative_data_path = '/content/Running_Example_v5_rt 0 0 .csv'\n",
        "representative_data_path = '/content/Running_Example_v5_rt 15 10.csv'\n",
        "\n",
        "\n",
        "\n",
        "#Verifica se o arquivo existe. Se não, lança um erro FileNotFoundError.\n",
        "#Checks if the file exists. If not, throws a FileNotFoundError.\n",
        "\n",
        "if not os.path.exists(representative_data_path):\n",
        "    raise FileNotFoundError(f\"File not found: {representative_data_path}\")\n",
        "\n",
        "\n",
        "\n",
        "#Abre o arquivo em modo leitura ('r') com codificação UTF-8.\n",
        "#Opens the file in read mode ('r') with UTF-8 encoding.\n",
        "\n",
        "#Lê todas as linhas do arquivo e armazena na variável representative_data_raw.\n",
        "#Reads all lines from the file and stores them in the representative_data_raw variable.\n",
        "\n",
        "#Se houver erro ao ler o arquivo, lança um erro RuntimeError.\n",
        "#If there is an error reading the file, throw a RuntimeError.\n",
        "\n",
        "try:\n",
        "    with open(representative_data_path, 'r', encoding='utf-8') as file:\n",
        "          representative_data_raw = file.readlines()\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Error reading file: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "#Define a função pre_processing, responsável por processar os dados do arquivo.\n",
        "#Defines the pre_processing function, responsible for processing the file data.\n",
        "\n",
        "def pre_processing():\n",
        "\n",
        "  # Parse the representative file to extract structured information\n",
        "  #Analisa o arquivo representativo para extrair informações estruturadas\n",
        "  def parse_representative_data(raw_lines):\n",
        "    global aspects\n",
        "\n",
        "\n",
        "    #Cria um dicionário para armazenar três seções: metadata, settings e trajectory_description.\n",
        "    #Creates a dictionary to store three sections: metadata, settings and trajectory_description.\n",
        "    parsed_data = {\n",
        "        \"metadata\": {},\n",
        "        \"settings\": {},\n",
        "        \"trajectory_description\": []\n",
        "    }\n",
        "\n",
        "\n",
        "    #Remove espaços extras no início e fim de cada linha.\n",
        "    #Remove extra spaces at the beginning and end of each line.\n",
        "    current_section = None\n",
        "    for line in raw_lines:\n",
        "        line = line.strip()\n",
        "\n",
        "\n",
        "        #Identifica qual seção do arquivo está sendo processada e define current_section de acordo.\n",
        "        #Identifies which section of the file is being processed and sets current_section accordingly.\n",
        "        if \"Info input dataset:\" in line:\n",
        "            current_section = \"metadata\"\n",
        "        elif \"RT setting infos:\" in line:\n",
        "            current_section = \"settings\"\n",
        "        elif \"RT description:\" in line:\n",
        "            current_section = \"trajectory_description\"\n",
        "        elif line.startswith(\"##\"):\n",
        "            current_section = None  # End of a section | Fim de uma seção\n",
        "\n",
        "\n",
        "        #Se estiver na seção metadata, armazena os pares chave-valor.\n",
        "        #If in the metadata section, stores key-value pairs.\n",
        "        elif current_section == \"metadata\":\n",
        "            #Analisar pares de chave-valor de metadados\n",
        "            # Parse metadata key-value pairs\n",
        "            if re.match(r'\\|.*\\|', line):  # Header line for metadata | Linha de cabeçalho para metadados\n",
        "                headers = [h.strip() for h in line.split(\",\")]\n",
        "            else:\n",
        "                values = [v.strip() for v in line.split(\",\")]\n",
        "                for h, v in zip(headers, values):\n",
        "                    parsed_data[\"metadata\"][h] = v\n",
        "\n",
        "\n",
        "        #Se estiver na seção settings, armazena as configurações do arquivo.\n",
        "        #If it is in the settings section, it stores the file settings.\n",
        "        elif current_section == \"settings\":\n",
        "            #Detalhes das configurações de análise\n",
        "            # Parse settings details\n",
        "            if re.match(r'thresholdCellSize', line):  # Header line for settings | Linha de cabeçalho para configurações\n",
        "                settings_headers = [h.strip() for h in line.split(\",\")]\n",
        "            else:\n",
        "                settings_values = [v.strip() for v in line.split(\",\")]\n",
        "                for h, v in zip(settings_headers, settings_values):\n",
        "                    parsed_data[\"settings\"][h] = v\n",
        "\n",
        "\n",
        "        #Se estiver na seção trajectory_description, armazena os dados da trajetória do objeto.\n",
        "        #If in the trajectory description section, stores the object's trajectory data.\n",
        "        elif current_section == \"trajectory_description\":\n",
        "            #Analisar linhas de descrição de trajetória\n",
        "            # Parse trajectory description lines\n",
        "            if re.match(r'lat_lon', line):  # Header line for trajectory description | Linha de cabeçalho para descrição da trajetória\n",
        "                trajectory_headers = [h.strip() for h in line.split(\",\")]\n",
        "            else:\n",
        "                trajectory_values = [v.strip() for v in line.split(\",\")]\n",
        "                parsed_data[\"trajectory_description\"].append(\n",
        "                    dict(zip(trajectory_headers, trajectory_values))\n",
        "                )\n",
        "\n",
        "\n",
        "            #Define aspects globalmente para armazenar os aspectos analisados.\n",
        "            #Define aspects globally to store the analyzed aspects.\n",
        "            aspects = trajectory_headers\n",
        "    return parsed_data\n",
        "\n",
        "\n",
        "\n",
        "  #Processa os dados do arquivo e imprime a estrutura gerada.\n",
        "  #Process the file data and print the generated structure.\n",
        "  structured_data = parse_representative_data(representative_data_raw)\n",
        "  print(structured_data)\n",
        "\n",
        "\n",
        "  #Define os aspectos a serem analisados: Ponto de Interesse (POI) e Clima (WEATHER).\n",
        "  #Define the aspects to be analyzed: Point of Interest (POI) and Weather.\n",
        "  aspects_to_analyze = ['POI', 'WEATHER']\n",
        "\n",
        "\n",
        "\n",
        "  #Analisa padrões comuns nos aspectos especificados.\n",
        "  #Analyzes common patterns in the specified aspects.\n",
        "  def analyze_aspect_patterns(data, aspects):\n",
        "      \"\"\"Analyzes trajectory data for common patterns in specified aspects.\"\"\"\n",
        "      trajectory = data[\"trajectory_description\"]\n",
        "      aspects_to_analyze = aspects\n",
        "\n",
        "\n",
        "\n",
        "      #Cria um dicionário para armazenar contagens de valores observados nos aspectos.\n",
        "      #Creates a dictionary to store counts of observed values ​​in aspects.\n",
        "      patterns = defaultdict(lambda: {\"values\": defaultdict(int), \"count\": 0})\n",
        "\n",
        "\n",
        "\n",
        "      # Itera sobre a descrição da trajetória.\n",
        "      #Iterate over the trajectory description.\n",
        "      for aspect in trajectory:\n",
        "        print(f\"Aspect: {aspect}\")\n",
        "\n",
        "\n",
        "\n",
        "        # Conta quantas vezes cada valor aparece para cada aspecto.\n",
        "        #Counts how many times each value appears for each aspect.\n",
        "        for aspect_name in aspects_to_analyze:\n",
        "          if aspect_name in aspect:\n",
        "              patterns[aspect_name][\"count\"] += 1\n",
        "              patterns[aspect_name][\"values\"][aspect[aspect_name]] += 1\n",
        "\n",
        "      summary_parts = []\n",
        "\n",
        "      for aspect_name, pattern_data in patterns.items():\n",
        "          if pattern_data[\"count\"] > 0:\n",
        "              values_dict = pattern_data[\"values\"]\n",
        "              if len(values_dict) == 1:\n",
        "                  value = next(iter(values_dict))\n",
        "                  summary_parts.append(f\"Usually, the object's {aspect_name.lower()} is {value}\")\n",
        "              elif aspect_name == 'PRICE':\n",
        "                  prices = []\n",
        "                  for key, value in values_dict.items():\n",
        "                    match = re.findall(r'\\*(\\d+):\\s*([\\d\\.]+)', key)\n",
        "                    if match:\n",
        "                        for m in match:\n",
        "                          prices.append(float(m[0]))\n",
        "\n",
        "                  if prices:\n",
        "                    min_price = min(prices)\n",
        "                    max_price = max(prices)\n",
        "                    summary_parts.append(f\"The evaluation of price in referred place is defined between {min_price} and {max_price}\")\n",
        "\n",
        "              else:\n",
        "                  most_frequent_value = max(pattern_data[\"values\"], key=pattern_data[\"values\"].get)\n",
        "                  if pattern_data[\"values\"][most_frequent_value] == pattern_data[\"count\"]:\n",
        "                    summary_parts.append(f\"Usually, the object's {aspect_name.lower()} is {most_frequent_value}\")\n",
        "\n",
        "      return \" \".join(summary_parts)\n",
        "\n",
        "\n",
        "\n",
        "  # Gera um resumo dos dados processados.\n",
        "  #Generates a summary of the processed data.\n",
        "  def generate_summary(data):\n",
        "\n",
        "\n",
        "\n",
        "      # Resume a quantidade de trajetórias e pontos.\n",
        "      #Summarizes the number of trajectories and points.\n",
        "      metadata_summary = (\n",
        "          f\"The representative dataset contains {data['metadata'].get('|input.T|', 'N/A')} trajectories \"\n",
        "          f\"with a total of {data['metadata'].get('|input.T.points|', 'N/A')} points.\\n\"\n",
        "      )\n",
        "\n",
        "\n",
        "\n",
        "      # Resume as configurações utilizadas na análise.\n",
        "      #Summarizes the settings used in the analysis.\n",
        "      settings = data[\"settings\"]\n",
        "      settings_summary = (\n",
        "          \"The analysis used the following parameters:\\n\"\n",
        "          f\"- Threshold Cell Size: {settings.get('thresholdCellSize', 'N/A')}\\n\"\n",
        "          f\"- Cell Size: {settings.get('CellSize', 'N/A')}\\n\"\n",
        "          f\"- Relevant Cell Threshold: {settings.get('tauRelevantCell', 'N/A')}\\n\"\n",
        "          f\"- Representativeness Value Threshold: {settings.get('tauRepresentativenessValue', 'N/A')}\\n\"\n",
        "          f\"- Runtime: {settings.get('runtime start', 'N/A')} to {settings.get('runtime end', 'N/A')}.\\n\"\n",
        "      )\n",
        "\n",
        "      #Resumo da descrição da trajetória\n",
        "      # Trajectory description summary\n",
        "      trajectory = data[\"trajectory_description\"]\n",
        "\n",
        "\n",
        "\n",
        "      # Lista eventos da trajetória do objeto.\n",
        "      #List events from the object's trajectory.\n",
        "      trajectory_summary = \"Key trajectory events:\\n\"\n",
        "      for aspect in trajectory:\n",
        "          trajectory_summary += (\n",
        "              f\"  - At {aspect.get('time', 'N/A')}, the object was at location {aspect.get('lat_lon', 'N/A')} \"\n",
        "              f\"({aspect.get('POI', 'N/A')}) under {aspect.get('WEATHER', 'N/A')} weather conditions \"\n",
        "              f\"with precipitation of {aspect.get('PRECIP', 'N/A')} mm.\\n\"\n",
        "          )\n",
        "\n",
        "\n",
        "\n",
        "      # Chama a função de análise de padrões.\n",
        "      #Call the pattern analysis function.\n",
        "      trajectory_patterns_summary = analyze_aspect_patterns(data, aspects=aspects_to_analyze)\n",
        "\n",
        "\n",
        "\n",
        "      # Retorna um resumo completo.\n",
        "      #Returns a complete summary.\n",
        "      summary = metadata_summary + settings_summary + trajectory_summary + trajectory_patterns_summary\n",
        "      return summary\n",
        "\n",
        "\n",
        "  #Gera um resumo para os dados representativos\n",
        "  # Generate a summary for the representative data\n",
        "  summary = generate_summary(structured_data)\n",
        "\n",
        "\n",
        "\n",
        "  # Classifica um horário em manhã, tarde, noite ou madrugada.\n",
        "  #Classifies a time as morning, afternoon, evening or night.\n",
        "  def time_of_day(hour):\n",
        "      \"\"\"Categorize an hour into morning, afternoon, evening, or night.\"\"\"\n",
        "      if 5 <= hour < 12:\n",
        "          return \"morning\"\n",
        "      elif 12 <= hour < 17:\n",
        "          return \"afternoon\"\n",
        "      elif 17 <= hour < 21:\n",
        "          return \"evening\"\n",
        "      else:\n",
        "          return \"night\"\n",
        "\n",
        "\n",
        "\n",
        "  # Formata descrições de POI.\n",
        "  #Formats POI descriptions\n",
        "  def format_poi(poi):\n",
        "      \"\"\"Format POI descriptions to be more human-readable.\"\"\"\n",
        "      if \"1.0\" in poi:  # If the frequency is 100%, use a simpler phrase | Se a frequência for 100%, use uma frase mais simples\n",
        "          poi_name = poi.split(\":\")[0].strip(\"{}\")  # Extract the POI name | Extraia o nome do POI\n",
        "          return f\"at {poi_name.lower()}\"\n",
        "\n",
        "      return poi.replace(\"at \", \"\").strip()  # Remove extra \"at\" from transitions | Remover \"at\" extra das transições\n",
        "\n",
        "\n",
        "\n",
        "  # Formata informações meteorológicas.\n",
        "  #Formats weather information.\n",
        "  def format_weather(weather):\n",
        "      \"\"\"Format weather conditions to include frequency density.\"\"\"\n",
        "      matches = re.findall(r'{(.*?):\\s*([\\d\\.]+)}', weather)\n",
        "      if matches:\n",
        "          conditions = []\n",
        "          for condition, freq in matches:\n",
        "              freq = float(freq)\n",
        "              if freq == 1.0:\n",
        "                  conditions.append(f\"{condition.lower()} (100% frequency)\")\n",
        "              else:\n",
        "                  percentage = int(freq * 100)\n",
        "                  conditions.append(f\"{condition.lower()} ({percentage}%)\")\n",
        "          return \" and \".join(conditions)\n",
        "\n",
        "\n",
        "      return weather\n",
        "\n",
        "  return structured_data, time_of_day, format_weather, format_poi\n",
        "\n",
        "\n",
        "\n",
        "# Chama a função pre_processing, que retorna os dados processados e funções auxiliares.\n",
        "#Call the pre_processing function, which returns the processed data, and auxiliary functions.\n",
        "structured_data, time_of_day, format_weather, format_poi = pre_processing()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zPn9aYevUIoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29eae575-e158-4f00-e67b-0f221ff0dc7f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'metadata': {'|input.T|': '3', '|input.T.points|': '17'}, 'settings': {'thresholdCellSize': '9', 'CellSize': '4.602687082099914', 'tauRelevantCell': '0.15', 'tauRepresentativenessValue': '0.1', '|cell|': '5', 'minPointRC': '2.5500002', '|rt|': '14', '|coverPoints|': '16', 'runtime start': '23-07-07 14:41:12.958', 'runtime end': '23-07-07 14:41:13.275'}, 'trajectory_description': [{'lat_lon': '0.0 6.2', 'time': '05:45', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{1: 1}'}, {'lat_lon': '0.4 6.7', 'time': '06:15', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '15.0', 'mapping': '{2: 7}'}, {'lat_lon': '1.0 6.8', 'time': '06:50', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{3: 13}'}, {'lat_lon': '2.5 10.5', 'time': '10:10', 'PRICE': '{*2: 1.0}', 'POI': '{LIBRARY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{2: 8}'}, {'lat_lon': '4.0 14.5', 'time': '10:35', 'PRICE': '{*2: 1.0}', 'POI': '{SHOPPING: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{3: 14}'}, {'lat_lon': '0.8 6.2', 'time': '11:57', 'PRICE': '{*2: 1.0}', 'POI': '{LIBRARY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '20.0', 'mapping': '{1: 2}'}, {'lat_lon': '3.0 13.5', 'time': '12:20', 'PRICE': '{*3: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '20.0', 'mapping': '{2: 9}'}, {'lat_lon': '4.3 17.9', 'time': '14:15', 'PRICE': '{*-1: 1.0}', 'POI': '{UNIVERSITY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{3: 15}'}, {'lat_lon': '3.1 11.0', 'time': '17:12', 'PRICE': '{*2: 1.0}', 'POI': '{SHOPPING: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{1: 3}'}, {'lat_lon': '6.3 13.1', 'time': '18:00', 'PRICE': '{*1: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{3: 16}'}, {'lat_lon': '4.3 16.9', 'time': '19:39', 'PRICE': '{*-1: 1.0}', 'POI': '{UNIVERSITY: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '0.0', 'mapping': '{1: 4}'}, {'lat_lon': '6.3 13.0', 'time': '21:23', 'PRICE': '{*1: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{2: 11}'}, {'lat_lon': '6.2 12.05', 'time': '22:15 - 22:24', 'PRICE': '{*1: 0.5; *2: 0.5}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '5.0', 'mapping': '{1: 5; 3: 17}'}, {'lat_lon': '0.5 6.55', 'time': '23:20 - 23:30', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '12.5', 'mapping': '{1: 6; 2: 12}'}]}\n",
            "Aspect: {'lat_lon': '0.0 6.2', 'time': '05:45', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{1: 1}'}\n",
            "Aspect: {'lat_lon': '0.4 6.7', 'time': '06:15', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '15.0', 'mapping': '{2: 7}'}\n",
            "Aspect: {'lat_lon': '1.0 6.8', 'time': '06:50', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{3: 13}'}\n",
            "Aspect: {'lat_lon': '2.5 10.5', 'time': '10:10', 'PRICE': '{*2: 1.0}', 'POI': '{LIBRARY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{2: 8}'}\n",
            "Aspect: {'lat_lon': '4.0 14.5', 'time': '10:35', 'PRICE': '{*2: 1.0}', 'POI': '{SHOPPING: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{3: 14}'}\n",
            "Aspect: {'lat_lon': '0.8 6.2', 'time': '11:57', 'PRICE': '{*2: 1.0}', 'POI': '{LIBRARY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '20.0', 'mapping': '{1: 2}'}\n",
            "Aspect: {'lat_lon': '3.0 13.5', 'time': '12:20', 'PRICE': '{*3: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '20.0', 'mapping': '{2: 9}'}\n",
            "Aspect: {'lat_lon': '4.3 17.9', 'time': '14:15', 'PRICE': '{*-1: 1.0}', 'POI': '{UNIVERSITY: 1.0}', 'WEATHER': '{CLOUDS: 1.0}', 'PRECIP': '15.0', 'mapping': '{3: 15}'}\n",
            "Aspect: {'lat_lon': '3.1 11.0', 'time': '17:12', 'PRICE': '{*2: 1.0}', 'POI': '{SHOPPING: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{1: 3}'}\n",
            "Aspect: {'lat_lon': '6.3 13.1', 'time': '18:00', 'PRICE': '{*1: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{3: 16}'}\n",
            "Aspect: {'lat_lon': '4.3 16.9', 'time': '19:39', 'PRICE': '{*-1: 1.0}', 'POI': '{UNIVERSITY: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '0.0', 'mapping': '{1: 4}'}\n",
            "Aspect: {'lat_lon': '6.3 13.0', 'time': '21:23', 'PRICE': '{*1: 1.0}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '10.0', 'mapping': '{2: 11}'}\n",
            "Aspect: {'lat_lon': '6.2 12.05', 'time': '22:15 - 22:24', 'PRICE': '{*1: 0.5; *2: 0.5}', 'POI': '{RESTAURANT: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '5.0', 'mapping': '{1: 5; 3: 17}'}\n",
            "Aspect: {'lat_lon': '0.5 6.55', 'time': '23:20 - 23:30', 'PRICE': '{*-1: 1.0}', 'POI': '{HOME: 1.0}', 'WEATHER': '{CLEAR: 1.0}', 'PRECIP': '12.5', 'mapping': '{1: 6; 2: 12}'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from pickle import EMPTY_DICT\n",
        "\n",
        "import re\n",
        "from datetime import datetime # Importa a classe datetime, utilizada para manipular e formatar datas e horas.\n",
        "from jinja2 import Template # Importa Template da biblioteca jinja2, que permite criar templates para gerar texto estruturado.\n",
        "\n",
        "\n",
        "\n",
        "# Define a função textual_descriptor, que gera uma descrição textual baseada nos dados estruturados de trajetórias (structured_data).\n",
        "#Defines the textual_descriptor function, which generates a textual description based on structured trajectory data (structured_data).\n",
        "\n",
        "# Também recebe as funções auxiliares time_of_day, format_weather e format_poi, usadas para classificar horários, formatar condições climáticas e locais visitados.\n",
        "#It also receives the auxiliary functions time_of_day, format_weather and format_poi, used to classify times, format weather conditions and places visited.\n",
        "def textual_descriptor(structured_data, time_of_day, format_weather, format_poi):\n",
        "\n",
        "  '''\n",
        "  função já faz parte do 'Textual Descriptor'.\n",
        "\n",
        "  '''\n",
        "\n",
        "\n",
        "\n",
        "  # Define uma função interna para gerar um resumo narrativo dos eventos de trajetória.\n",
        "  #Defines an internal function to generate a narrative summary of trajectory events.\n",
        "  def generate_narrative_summary(data):\n",
        "      \"\"\"Generate a narrative summary of the trajectory data.\"\"\"\n",
        "      trajectory = data[\"trajectory_description\"]\n",
        "\n",
        "      #Eventos de grupo por hora do dia\n",
        "      # Group events by time of day\n",
        "      time_groups = defaultdict(list)\n",
        "      for event in trajectory:\n",
        "          time_str = event.get(\"time\", \"\").split(\"-\")[0].strip()  # Use start time and strip trailing space | Use a hora de início e retire o espaço final\n",
        "          hour = int(time_str.split(\":\")[0])  # Extract the hour | Extrai a hora\n",
        "          period = time_of_day(hour)\n",
        "          time_groups[period].append(event)\n",
        "\n",
        "      #Gerar narrativa para cada grupo de tempo\n",
        "      # Generate narrative for each time group\n",
        "      summary_parts = []\n",
        "      for period, events in time_groups.items():\n",
        "          poi_counts = defaultdict(int)\n",
        "          weather_counts = defaultdict(int)\n",
        "          transitions = []\n",
        "\n",
        "          for i, event in enumerate(events):\n",
        "              poi = event.get(\"POI\", \"N/A\")\n",
        "              weather = event.get(\"WEATHER\", \"N/A\")\n",
        "              poi_counts[poi] += 1\n",
        "              weather_counts[weather] += 1\n",
        "\n",
        "              #Acompanha transições entre locais\n",
        "              # Track transitions between locations\n",
        "              if i > 0:\n",
        "                  prev_poi = events[i - 1].get(\"POI\", \"N/A\")\n",
        "                  if poi != prev_poi:\n",
        "                      transitions.append(\n",
        "                          f\"At {event['time']}, the object moved from {format_poi(prev_poi)} to at {format_poi(poi)}.\"\n",
        "                      )\n",
        "\n",
        "          #Resumi os POI e o clima mais frequentes\n",
        "          # Summarize the most frequent POI and weather\n",
        "          most_common_poi = max(poi_counts, key=poi_counts.get)\n",
        "          most_common_weather = max(weather_counts, key=weather_counts.get)\n",
        "          formatted_weather = format_weather(most_common_weather)\n",
        "          summary_parts.append(\n",
        "              f\"In the {period}, the object is usually {format_poi(most_common_poi)} \"\n",
        "              f\"with weather conditions {formatted_weather}.\"\n",
        "          )\n",
        "\n",
        "          #Adiciona transições se existirem\n",
        "          # Add transitions if they exist\n",
        "          if transitions:\n",
        "              summary_parts.extend(transitions)\n",
        "\n",
        "      #Combine todos os resumos em uma narrativa coesa\n",
        "      # Combine all summaries into a cohesive narrative\n",
        "      return \" \".join(summary_parts)\n",
        "\n",
        "  #Exemplo de uso:\n",
        "  # Example usage:\n",
        "  narrative_summary = generate_narrative_summary(structured_data)\n",
        "  #print(narrative_summary)\n",
        "\n",
        "  def refine_summary_text(summary_text):\n",
        "      \"\"\"Refines the summary text to improve readability and remove redundant words.\"\"\"\n",
        "      summary_text = summary_text.replace(\"frequently in \", \"at \")\n",
        "      summary_text = summary_text.replace(\"with weather conditions\", \"with\")\n",
        "\n",
        "      # Improve readability by ensuring correct sentence structure\n",
        "      #summary_text = re.sub(r'\\s+', ' ', summary_text)  # Remove extra spaces\n",
        "      #summary_text = summary_text.replace(\" - \", \"–\")  # Replace hyphen with en dash for time ranges\n",
        "\n",
        "      return summary_text\n",
        "\n",
        "  #Normalize os espaços e substitua os traços uma vez, em vez de em vários lugares\n",
        "  # Normalize spaces & replace dashes once, instead of in multiple places\n",
        "  def preprocess_text(input_text):\n",
        "      \"\"\"Cleans and normalizes input text for parsing.\"\"\"\n",
        "      input_text = re.sub(r\"\\s+\", \" \", input_text.strip())  # Normalize spaces | Normalizar espaços\n",
        "      input_text = input_text.replace(\" - \", \"–\")  # Replace dashes | Substituir travessões\n",
        "      input_text = input_text.replace(\"–\", \"-\")\n",
        "      return input_text\n",
        "\n",
        "  refined_summary = refine_summary_text(narrative_summary)\n",
        "  print(refined_summary)\n",
        "\n",
        "  usuario = input(\"Digite o nome do usuário (ou pressione Enter para usar 'The object'): \").strip()\n",
        "  if not usuario:\n",
        "      usuario = \"object\"  # Default value | Valor padrão\n",
        "\n",
        "\n",
        "  # Template de saída\n",
        "  '''\n",
        "\n",
        "  '''\n",
        "  template_text = \"\"\"\n",
        "  {% for period in data %}\n",
        "  In the {{ period.time_period }}, the \"\"\" + usuario + \"\"\" is usually at {{ period.poi }}{% if period.weather and \"100% frequency\" not in period.weather %} with {{ period.weather }}{% endif %}.\n",
        "  {% for transition in period.transitions %}\n",
        "  At {{ transition.time }}, the \"\"\" + usuario + \"\"\" moves from {{ transition.from_poi }} to {{ transition.to_poi.split(',')[0] }}.{% if not loop.last %} Then, {% endif %}\n",
        "  {% endfor %}\n",
        "  {% endfor %}\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  input_text = preprocess_text(refined_summary)\n",
        "\n",
        "  def parse_input_text(input_text):\n",
        "      \"\"\"Analisa o texto e estrutura os dados para o template.\"\"\"\n",
        "      time_period_pattern = r\"In the (\\w+), the object is usually at ([\\w\\s]+)(?: with [\\w\\s]+ \\(\\d+% frequency\\))?\\.\"\n",
        "      transition_pattern = r\"At\\s+([\\d:–]+)(?:-\\d{2}:\\d{2})?, the object moved from(?: at)? ([\\w\\s]+) to(?: at)? (?:\\{([^}]+)\\}|([\\w\\s]+))\\.\"\n",
        "\n",
        "      # Extrair períodos do dia\n",
        "      # extract the periods of the day\n",
        "      time_periods = re.findall(time_period_pattern, input_text)\n",
        "\n",
        "      # Extrair transições\n",
        "      #Extract transitions\n",
        "      transitions = re.findall(transition_pattern, input_text)\n",
        "      #print(transitions)\n",
        "\n",
        "      def extract_best_destination(to_pois):\n",
        "          \"\"\"Extracts the best destination based on frequency values.\"\"\"\n",
        "          if not to_pois:\n",
        "              return \"unknown location\"\n",
        "\n",
        "          destinations = re.findall(r\"([A-Z]+): ([\\d.]+)\", to_pois)\n",
        "          if destinations:\n",
        "              best_destination = sorted(destinations, key=lambda x: (-float(x[1]), x[0]))[0][0]\n",
        "              return best_destination\n",
        "          return to_pois.strip()\n",
        "\n",
        "\n",
        "      def get_period_for_time(time_str):\n",
        "          \"\"\"Retorna o período do dia baseado na hora fornecida.\"\"\"\n",
        "          period_boundaries = {\n",
        "              \"morning\": (6, 11),\n",
        "              \"afternoon\": (12, 17),\n",
        "              \"evening\": (18, 21),\n",
        "              \"night\": (22, 5),  # Night começa às 22:00 e vai até 05:59 | Night start at 22:00 e lasts until 05:59\n",
        "          }\n",
        "\n",
        "          time_obj = datetime.strptime(time_str, \"%H:%M\")\n",
        "          hour = time_obj.hour\n",
        "\n",
        "          for period, (start_hour, end_hour) in period_boundaries.items():\n",
        "              if start_hour <= end_hour:  # Intervalos normais (morning, afternoon, evening) | Normal intervals (morning, afternoon, evening)\n",
        "                  if start_hour <= hour <= end_hour:\n",
        "                      return period\n",
        "              else:  # Caso especial para \"night\" que cruza a meia-noite (22h - 05h) | Especial case for night que cross midnight(22 - 05)\n",
        "                  if hour >= start_hour or hour <= end_hour:\n",
        "                      return period\n",
        "          return \"night\"\n",
        "\n",
        "      # Estruturar os dados com as transições divididas por período\n",
        "      #Structure the data with the transitions divided by period\n",
        "      structured_data = []\n",
        "      for time_period, poi in time_periods:\n",
        "          transitions_in_period = []\n",
        "\n",
        "          # Filtrar transições para o período atual\n",
        "          #Filter transitions for the current period\n",
        "\n",
        "          for time, from_poi, to_pois_1, to_pois_2 in transitions:\n",
        "                period = get_period_for_time(time)\n",
        "                to_pois = to_pois_1 if to_pois_1 else to_pois_2  # Ensure correct destination format | Garantir o formato correto do destino\n",
        "\n",
        "                if period == time_period.lower():\n",
        "                    best_destination = extract_best_destination(to_pois)\n",
        "                    transitions_in_period.append({\n",
        "                        \"time\": time.strip(),\n",
        "                        \"from_poi\": from_poi.strip(),\n",
        "                        \"to_poi\": best_destination.strip(),\n",
        "                    })\n",
        "\n",
        "\n",
        "          structured_data.append({\n",
        "              \"time_period\": time_period.lower(),\n",
        "              \"poi\": poi.strip(),\n",
        "              \"transitions\": transitions_in_period\n",
        "          })\n",
        "\n",
        "      return structured_data\n",
        "\n",
        "  def generate_summary(data):\n",
        "      \"\"\"Gera um resumo\"\"\"\n",
        "      summary = []\n",
        "      for period in data:\n",
        "          transitions = period[\"transitions\"]\n",
        "          summary.append(\n",
        "              f\"In the {period['time_period']}, the {usuario} is usually at {period['poi']}.\"\n",
        "          )\n",
        "          if transitions:\n",
        "              for transition in transitions:\n",
        "                  summary.append(\n",
        "                      f\"Then the {usuario} goes to {transition['to_poi']}.\"\n",
        "                  )\n",
        "      return \"\\n\".join(summary)\n",
        "\n",
        "  # Parse do texto de entrada\n",
        "  #Parse the input text\n",
        "  structured_data = parse_input_text(input_text)\n",
        "\n",
        "  # Verificar se a transição foi reconhecida\n",
        "  #Verify if the transition was recognized\n",
        "  '''\n",
        "  for period in structured_data_new:\n",
        "      print(f\"Período: {period['time_period']}, Transições: {period['transitions']}\")\n",
        "  '''\n",
        "\n",
        "  # Renderizar o template\n",
        "  #Render the template\n",
        "  template = Template(template_text)\n",
        "  output_jinja = template.render(data=structured_data)\n",
        "\n",
        "  summary = generate_summary(structured_data)\n",
        "\n",
        "  # Imprimir os resultados\n",
        "  #Print the result\n",
        "  print(\"=== Texto Gerado ===\")\n",
        "  print(output_jinja)\n",
        "  print(\"\\n=== Resumo ===\")\n",
        "  print(summary)\n",
        "\n",
        "textual_descriptor(structured_data, time_of_day, format_weather, format_poi)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OEQCQSB50Wp",
        "outputId": "e54b668d-de9d-4163-8285-17158bb0e886"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In the morning, the object is usually at home with clear (100% frequency). At 10:10, the object moved from at home to at at library. At 10:35, the object moved from at library to at at shopping. At 11:57, the object moved from at shopping to at at library. In the afternoon, the object is usually at restaurant with clouds (100% frequency). At 14:15, the object moved from at restaurant to at at university. In the evening, the object is usually at shopping with clear (100% frequency). At 18:00, the object moved from at shopping to at at restaurant. At 19:39, the object moved from at restaurant to at at university. In the night, the object is usually at restaurant with clear (100% frequency). At 23:20 - 23:30, the object moved from at restaurant to at at home.\n",
            "Digite o nome do usuário (ou pressione Enter para usar 'The object'): test\n",
            "=== Texto Gerado ===\n",
            "\n",
            "  \n",
            "  In the morning, the test is usually at home.\n",
            "  \n",
            "  At 10:10, the test moves from home to at library. Then, \n",
            "  \n",
            "  At 10:35, the test moves from library to at shopping. Then, \n",
            "  \n",
            "  At 11:57, the test moves from shopping to at library.\n",
            "  \n",
            "  \n",
            "  In the afternoon, the test is usually at restaurant.\n",
            "  \n",
            "  At 14:15, the test moves from restaurant to at university.\n",
            "  \n",
            "  \n",
            "  In the evening, the test is usually at shopping.\n",
            "  \n",
            "  At 18:00, the test moves from shopping to at restaurant. Then, \n",
            "  \n",
            "  At 19:39, the test moves from restaurant to at university.\n",
            "  \n",
            "  \n",
            "  In the night, the test is usually at restaurant.\n",
            "  \n",
            "  At 23:20, the test moves from restaurant to at home.\n",
            "  \n",
            "  \n",
            "  \n",
            "\n",
            "=== Resumo ===\n",
            "In the morning, the test is usually at home.\n",
            "Then the test goes to at library.\n",
            "Then the test goes to at shopping.\n",
            "Then the test goes to at library.\n",
            "In the afternoon, the test is usually at restaurant.\n",
            "Then the test goes to at university.\n",
            "In the evening, the test is usually at shopping.\n",
            "Then the test goes to at restaurant.\n",
            "Then the test goes to at university.\n",
            "In the night, the test is usually at restaurant.\n",
            "Then the test goes to at home.\n"
          ]
        }
      ]
    }
  ]
}
